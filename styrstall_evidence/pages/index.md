---
title: Exploring Bike Sharing Data in Gothenburg City - Styr och Ställ
---
*Techniques/tools used: python, dagster, dbt, evidence and azure storage*
## Introduction

In the city of Gothenburg, the Styr och Ställ bike sharing system plays a crucial role in promoting sustainable and efficient urban transportation. This project aims to look into the data generated by the Styr och Ställ bike sharing stations and present insights that can contribute to a better understanding of mobility patterns and usage trends.

### Objectives

1. **Usage Patterns Analysis**: Investigate how Styr och Ställ bikes are utilized throughout different times of the day, days of the week, and seasons.

2. **User Behavior Exploration**: Explore user behavior, identifying popular routes, and any emerging patterns that may influence the system's optimization.

3. **Station Performance Metrics**: Evaluate the performance of individual bike sharing stations, considering factors such as bike availability, station popularity, and user satisfaction.

### Data Sources

The primary data sources for this project include:

- **Styr och Ställ API**: Gothenburg city is providing an open API for real-time data on bike availability, station status, and usage statistics.
  
- **Frost weather API**: Frost API provides access to MET Norway's archive of historical weather and climate data.

## Data Pipeline

### Data Collection:

The primary source of data for this project is the Styr och Ställ bike sharing system's API. The API provides real-time data on various facets of the bike sharing service. Information includes station id and name, station cordinates, bike availability. Additionally, weather data is sourced from reliable meteorological services to correlate with bike sharing patterns. The orchestration of data collection processes is managed through Dagster, a data orchestrator that ensures reliable and structured data retrieval. Python scripts are used for API integration.

The retrieval frequency for Styr och Ställ data is set at ten-minute intervals, while weather data is acquired on a daily basis. (ingestion - kafka? storage limitations?)


### Data Storage:

The collected data is stored in a datalake using Azure Storage. The data is organized in two containers, using blob-prefixes and is arranged in accordance with the following hierarchy.


Azure Storage <br>
&nbsp;&nbsp;|── raw (container)  <br>
&nbsp;&nbsp;|&nbsp;&nbsp;&nbsp;&nbsp;|── stations  <br>
&nbsp;&nbsp;|&nbsp;&nbsp;&nbsp;&nbsp;|&nbsp;&nbsp;&nbsp;&nbsp;└── YYYYMM  <br>
&nbsp;&nbsp;|&nbsp;&nbsp;&nbsp;&nbsp;|&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;└── stations_YYYYMMDDHHMM.json <br>
&nbsp;&nbsp;|&nbsp;&nbsp;&nbsp;&nbsp;|── weather  <br>
&nbsp;&nbsp;|&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;└── YYYYMM  <br>
&nbsp;&nbsp;|&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;└── weather_YYYYMMDD.json <br>
&nbsp;&nbsp;| <br>
&nbsp;&nbsp;|── stg (container)  <br>
&nbsp;&nbsp;|&nbsp;&nbsp;&nbsp;&nbsp;|── stations  <br>
&nbsp;&nbsp;|&nbsp;&nbsp;&nbsp;&nbsp;|&nbsp;&nbsp;&nbsp;&nbsp;└── stations_YYYYMM.parquet  <br>
&nbsp;&nbsp;|&nbsp;&nbsp;&nbsp;&nbsp;|── weather  <br>
&nbsp;&nbsp;|&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;└── weather_YYYYMM.parquet <br>

For processing, the data is transferred from the datalake to a duckdb database hosted locally. This local duckdb database serves as the foundation for subsequent data processing tasks, providing an efficient and accessible environment for analysis and manipulation.

### Data Processing:

Data processing is handled by dbt (data build tool), which includes cleaning, preprocessing, and transformation steps. Dbt ensures data integrity by addressing missing values, outlier detection, and normalization. Exploratory Data Analysis (EDA) is executed to derive initial insights.


### Data Usage:

The processed data is employed to derive actionable insights that align with the project objectives. Evidence is used to visualize the data and insights.


<!-- This demo [connects](/settings) to a local DuckDB file `dev.duckdb`. -->




<!-- 
<LineChart
  data={orders_by_month}
  y=sales
  yFmt=usd0k
  title = "Sales by Month, USD"
/>

## Write in Markdown

Evidence renders markdown files into web pages. This page is:
`[project]/pages/index.md`.

## Run SQL using Code Fences

```sql orders_by_month
select
  date_trunc('month', order_datetime) as order_month,
  count(*) as number_of_orders,
  sum(sales) as sales,
  sum(sales)/count(*) as average_order_value
from orders
where order_datetime >= '2020-01-01'
group by 1 order by 1 desc
```

In your markdown file, you can include SQL queries in code fences. Evidence will run these queries through your database and return the results to the page.

To see the queries on a page, click the 3-dot menu at the top right of the page and Show Queries. You can see both the SQL and the query results by interacting with the query above.


## Visualize Data with Components

### Value in Text

Last month customers placed **<Value data={orders_by_month} column=number_of_orders/>** orders. The AOV was **<Value data={orders_by_month} column=average_order_value fmt=usd2/>**.

### Big Value 
<BigValue data={orders_by_month} value=sales fmt=usd0/>
<BigValue data={orders_by_month} value=number_of_orders />


### Bar Chart

<BarChart 
  data={orders_by_month} 
  y=number_of_orders 
  fillColor="#488f96"
>
  <ReferenceArea xMin="2020-03-15" xMax="2021-05-15" label="COVID Impacted" color=red/>
</BarChart>

> **Try:** Change the chart to a `<LineChart>`.

### Data Table

<DataTable data={orders_by_month} rows=6/>

> **More:** See [all components](https://docs.evidence.dev/components/all-components)

# Share with Evidence Cloud

Evidence Cloud is the easiest way to securely share your project. 
- Get your project online
- Authenticate users
- Schedule data refreshes

  <BigLink href='https://du3tapwtcbi.typeform.com/waitlist?utm_source=cloud-page&typeform-source=evidence.dev'>Deploy to Evidence Cloud &rarr;</BigLink>

You can use Netlify, Vercel or another static hosting provider to [self-host Evidence](https://docs.evidence.dev/deployment/overview).

# Get Support

- Message us on [Slack](https://slack.evidence.dev/)
- Read the [Docs](https://docs.evidence.dev/)
- Open an issue on [Github](https://github.com/evidence-dev/evidence) -->
